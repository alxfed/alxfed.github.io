---
layout: post
title:  "A couple of practical questions about 'Machine Learning'"
excerpt: "It is more or less obvious that 'Machine Learning' (which should be properly called 'Machine Teaching') is here to stay. Now, how do we solve the problem of learning all these 'documentation' with cryptic terminology written by semi-educated half-wits?"
date:   2020-02-15  8:41 am
categories: blog posts
---
### My new self-assignment.
&nbsp;&nbsp;&nbsp;&nbsp;Now a couple of weeks ago I started researching in and
around this service, called [kibernetika.ai](https://kibernetika.ai/). It lets you organize and 
log the 'training' process of your models in a relatively straighforward way, then deploy the
microservice based on the newly trained model and make it available through the API. I got a demo
Kubernetes cluster there where I can (for the first time) experiment simultaneously with multiple
models on several frameworks, namely: Tensorflow, PyTorch, Spark/Pyspark/Toree; Intel's BigDL and 
OpenVINO... and I can, probably, try to create my own Kubernetes pod from my own Docker image too
(haven't tried it yet), but...! Here's the problem: in the same way as with 'clouds' it takes a lot
of time and effort to learn or re-learn (for the hundred-th time) one of these so called 'frameworks', 
if you know what I mean. And it's even harder to experiment with several of them in parallel, trying
to figure out which one of them is best for your particular problem. The main tragedy, as always
is in the fact that all these groups are trying to appropriate words and combinations of words
and make them a part of their 'brand'. Each 'company' invents its' own 'monkey language' and writes
a voluminous 'documentation' in it. <br>
### Many 'frameworks' promoting their (absolutely idiotic) terminology.
&nbsp;&nbsp;&nbsp;&nbsp;I found<br><br>Later.
