---
layout: post
title:  "Decompositions of Data and Models."
excerpt: "In the same way as popularization of Fourier transform and operational calculus by Weiner changed the technology of the 20-th century the 21-st century is calling for another type of decomposition techniques that will help solve many similar problems."
date:   2020-03-02  7:50 am
categories: blog posts
---
### Wiener did a great job.
&nbsp;&nbsp;&nbsp;&nbsp;He started it in the 30-s by popularizing the "Generalized
 harmonic analysis", then, of course, wrote the bible of all 20-th century engineers
 "Extrapolation, Interpolation and Smoothing". Where are we now with all that?
### The analogy between the Fourier Transform and Models/Learning
&nbsp;&nbsp;&nbsp;&nbsp;I had this blurred understanding for quite a while that
"I've seen it all before" when I kept looking through the achievements of Machine
Learning, Deep Learning, Neural Network Training and all that. Here's the analogy:
- The main idea of usefullness of Fourier transform comes from the fact that if 
you substitute an eigenfunction into a differential equation it is satisfied (by
definintion of an eigenfunction); if the equation is linear a substitution of any 
multiple of the eigenfunction has the same effect, the equation is satisfied. Then
why not 'decompose' the 'force', acting upon the system into a _linear_ combination
of eigenfunctions and watch their evolution separately, right? We will see 'resonances'
of 'harmonics' and all that stuff. That's how decomposition is usefull.
- So in this scheme, which is just a continuation of the idea of finding a particular 
solution of differential equation with initial conditions by using the 'undetermined 
coefficients', of more generally, for a 'force' on the right, a 'variation of 
parameters' (Euler, Lagrange, Duhamel or whoever) we seriously rely upon the 
superposition principle. And that's exactly why the Fourier series is a sum 
(superposition) of terms.
<br><br>Later.
