---
layout: post
title:  "Natural Language Processing and GitHub organizations"
subtitle: "Why I created all of these virtual organizations on GitHub."
date:   2019-01-19  9:19 am
categories: blog posts
---
<br><br>
There are several problems in the Natural Language Processing universe that I would like to explore. Namely:
* The problem of synthesizing a language for automated systems that will be communicating with humans. It's a two-fold problem that consists of two connected parts: inventing a classification of meanings similar to Roget's and developing algorithms that will synthesize the controlled language based on these ideas and a contemporary 'corpus' of texts;
* The overall problem of 'simplification' of English Language in a way that serves the purpose of communications in science and technology better than our present tendency of 'axiomatization' that took over Mathematics and Physics after the first third of the XX-th century and has gone rampant in the age of 'internet marketing' and wrongly understood 'branding';
* My personal studies of 'BASIC-english' of Ogden, 'Thesaurus of English words and __phrases__' of Roget and my attempts to modernize and update their ideas and achievements with the help of contemporary algorithmic and statistical toolset;
* My personal studies of 'Simple' wikipedia and wiktionary, of their achievements in use of synthetically simplified narrative. Maybe some of them can be used in the development of methodology and corpus of texts for robo-english;
* The materials that I found about the movement for 'Plain English' (an attempt to remove or minimize 'legalese' from everyday communications of humans).
<br>
